{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1835e819-2e2a-4812-a1e2-4c1344377a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import datasource, causal_cnn_models, modules, net_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44818305-451d-4ca1-ab9c-395ec79e8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def log(msg):\n",
    "    logger.debug(msg)\n",
    "\n",
    "\n",
    "def config_logger(log_file=None):\n",
    "    r\"\"\"Config logger.\"\"\"\n",
    "    global logger\n",
    "    logger.handlers.clear()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "    # create console handler and set level to debug\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    ch.setFormatter(format)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    # create file handler which logs even debug messages\n",
    "    if log_file:\n",
    "        fh = logging.FileHandler(log_file)\n",
    "        fh.setFormatter(format)\n",
    "        logger.addHandler(fh)\n",
    "\n",
    "\n",
    "def viz_epoch_batch(epoch, x_batch, x_hat_batch, log_path):\n",
    "    # folder = os.path.join(\"logs\", \"recon_vae\", log_filename)\n",
    "    folder = os.path.join(log_path, \"recon_vae\")\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    x_batch = x_batch.detach().cpu().numpy()\n",
    "    x_hat_batch = x_hat_batch.detach().cpu().numpy()\n",
    "    for i in range(1):\n",
    "        orig = x_batch[i, 0, :]\n",
    "        recon = x_hat_batch[i, 0, :]\n",
    "        _, ax = plt.subplots()\n",
    "        ax.plot(range(len(orig)), orig)\n",
    "        # plt.savefig(\n",
    "        #     f\"{folder}/epoch{epoch}_item{i}_orig.png\",\n",
    "        #     format='png', dpi=300, bbox_inches='tight')\n",
    "        ax.plot(range(len(recon)), recon)\n",
    "        # plt.ylim((0, 2)) \n",
    "        plt.savefig(\n",
    "            f\"{folder}/epoch{epoch}_item{i}.png\",\n",
    "            format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def save_models(model_file_instance_pairs):\n",
    "    for model_file in model_file_instance_pairs.keys():\n",
    "        net = model_file_instance_pairs.get(model_file)\n",
    "        torch.save(net.state_dict(), model_file)\n",
    "\n",
    "def load_models(model_file_instance_pairs, device=\"cpu\"):\n",
    "    for model_file in model_file_instance_pairs.keys():\n",
    "        net = model_file_instance_pairs.get(model_file)\n",
    "        net.load_state_dict(\n",
    "            torch.load(model_file, map_location=device))\n",
    "    # No return seems necessary, in-memory models updated.\n",
    "\n",
    "net_utils.fix_randomness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e8a7b2f-6c49-45e4-afd9-04a2c57d4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"Validation\"\n",
    "def init_load_models(params):\n",
    "    \"\"\"prepare model\"\"\"\n",
    "    params_decoder = params['decoder'].copy()\n",
    "    params_decoder['width'] = params['hz'] * params['seg_len_sec']\n",
    "    net = causal_cnn_models.FoldVaeClassifFoldWeight(\n",
    "        params['encoder'], params_decoder, n_split=params['n_split'], \n",
    "        n_class=params['n_class'], log=log, debug=False,\n",
    "    )\n",
    "\n",
    "    model_files = [\n",
    "        f\"{params['model_path']}/fold0_net.pt\", \n",
    "    ]\n",
    "    model_instances = [net]\n",
    "    load_models({\n",
    "        model_files[0]: model_instances[0].to(DEVICE),\n",
    "    }, device=DEVICE)\n",
    "    net.eval()\n",
    "    return model_instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f29809e-ef45-4eeb-bc16-582d64497191",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"Validation\"\n",
    "def init_load_models_z(params):\n",
    "    \"\"\"prepare model\"\"\"\n",
    "    params_decoder = params['decoder'].copy()\n",
    "    params_decoder['width'] = params['hz'] * params['seg_len_sec']\n",
    "    net = causal_cnn_models.FoldVaeClassifFoldWeightZ(\n",
    "        params['encoder'], params_decoder, n_split=params['n_split'], \n",
    "        n_class=params['n_class'], log=log, debug=False,\n",
    "    )\n",
    "\n",
    "    model_files = [\n",
    "        f\"{params['model_path']}/fold0_net.pt\", \n",
    "    ]\n",
    "    model_instances = [net]\n",
    "    load_models({\n",
    "        model_files[0]: model_instances[0].to(DEVICE),\n",
    "    }, device=DEVICE)\n",
    "    net.eval()\n",
    "    return model_instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2212bb01-f28f-4dcc-b88b-db2bc9d69f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data base-dir:/home/habib/data/mesa/polysomnography, data:set1x20, hz:100, class_map:{0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 2},\n",
      "No label for annot '9' in mesa-sleep-1901_annot.csv\n",
      "[mesa-sleep-1901_annot.csv] n_seg:1439, clz_lbl_dist:{0: 665, 1: 670, 2: 104}\n",
      "[mesa-sleep-1790_annot.csv] n_seg:1198, clz_lbl_dist:{0: 543, 1: 569, 2: 86}\n",
      "[mesa-sleep-1803_annot.csv] n_seg:632, clz_lbl_dist:{0: 282, 1: 302, 2: 48}\n",
      "[mesa-sleep-1917_annot.csv] n_seg:1435, clz_lbl_dist:{0: 661, 1: 651, 2: 123}\n",
      "Total files:4, n_seg:4704, distribution:(array([0, 1, 2]), array([2151, 2192,  361]))\n"
     ]
    }
   ],
   "source": [
    "test_rec_names = ['mesa-sleep-1790', 'mesa-sleep-1803', 'mesa-sleep-1901', 'mesa-sleep-1917']\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "ds = datasource.MesaDbCsv(\n",
    "    f\"{os.path.expanduser('~')}/data/mesa/polysomnography\", data_subdir=\"set1x20\",\n",
    "    hz=100, class_map=class_map, n_subjects=-1, hz_rr=5, \n",
    "    filter_records=test_rec_names,\n",
    "    is_rr_sig=False, is_rsp=False, is_ecg_beats=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18973af8-3bce-4064-8908-f4a60cf8d103",
   "metadata": {},
   "source": [
    "### FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923082611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6716f51b-25a3-4c32-852c-12c4009bfd56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 15:31:02,444 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 2, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 10, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923082611/models', 'n_class': 3}\n",
      "/tmp/ipykernel_271152/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 19200])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 300])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 300])\n",
      "[[337 193  13]\n",
      " [ 75 433  61]\n",
      " [ 17  59  10]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[162   8 112]\n",
      " [113  98  91]\n",
      " [ 22   7  19]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[409 131 125]\n",
      " [  0 661   9]\n",
      " [  0 102   2]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[363 272  26]\n",
      " [  2 541 108]\n",
      " [  0  76  47]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 10\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923082611/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models_z(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ade040-c795-4c2d-8fc9-2f51315d1c36",
   "metadata": {},
   "source": [
    "### FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240922190750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bedd0c8-9f8f-408a-8a56-92b27169d03c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 08:33:01,783 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 2, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 1, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240922190750/models', 'n_class': 3}\n",
      "/tmp/ipykernel_271152/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 192000])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 3000])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 3000])\n",
      "[[402 130  11]\n",
      " [177 351  41]\n",
      " [ 31  53   2]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[206   0  76]\n",
      " [ 64   3 235]\n",
      " [ 18   2  28]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[463 190  12]\n",
      " [289 372   9]\n",
      " [ 43  61   0]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[423 230   8]\n",
      " [ 25 610  16]\n",
      " [  2 110  11]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 1\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240922190750/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models_z(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22641a-1174-4c90-8443-2c3c36a73f72",
   "metadata": {},
   "source": [
    "### FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922213406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8514c11e-cc86-4346-9a54-3ee867f41702",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 08:30:04,484 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 2, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 5, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922213406/models', 'n_class': 3}\n",
      "/tmp/ipykernel_271152/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 38400])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 600])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 600])\n",
      "[[336 166  41]\n",
      " [ 55 407 107]\n",
      " [  7  74   5]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[161   1 120]\n",
      " [ 46  21 235]\n",
      " [ 15   1  32]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[414 148 103]\n",
      " [ 34 549  87]\n",
      " [  3 100   1]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[322 272  67]\n",
      " [  2 585  64]\n",
      " [  0  85  38]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 5\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/FoldVaeClassifFoldWeightZ_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922213406/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models_z(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047845b-758b-46a3-84a8-13a06cdb8cdb",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split15_ecgTrue_rrFalse_rspFalse_20240922084657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a543e6a4-e2f1-4ac8-9a8e-e5bb6e7bea3b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 17:23:30,913 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 2, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 15, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 3, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 3, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split15_ecgTrue_rrFalse_rspFalse_20240922084657/models', 'n_class': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FoldVaeClassifFoldWeight(\n",
      "  (encoder): CausalCNNVEncoder(\n",
      "    (network): Sequential(\n",
      "      (0): CausalCNN(\n",
      "        (network): Sequential(\n",
      "          (0): CausalConvolutionBlock(\n",
      "            (causal): Sequential(\n",
      "              (0): Conv1d(1, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "              (1): Chomp1d()\n",
      "              (2): LeakyReLU(negative_slope=0.01)\n",
      "              (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "              (4): Chomp1d()\n",
      "              (5): LeakyReLU(negative_slope=0.01)\n",
      "            )\n",
      "            (upordownsample): Conv1d(1, 128, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (1): CausalConvolutionBlock(\n",
      "            (causal): Sequential(\n",
      "              (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (1): Chomp1d()\n",
      "              (2): LeakyReLU(negative_slope=0.01)\n",
      "              (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "              (4): Chomp1d()\n",
      "              (5): LeakyReLU(negative_slope=0.01)\n",
      "            )\n",
      "          )\n",
      "          (2): CausalConvolutionBlock(\n",
      "            (causal): Sequential(\n",
      "              (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
      "              (1): Chomp1d()\n",
      "              (2): LeakyReLU(negative_slope=0.01)\n",
      "              (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
      "              (4): Chomp1d()\n",
      "              (5): LeakyReLU(negative_slope=0.01)\n",
      "            )\n",
      "          )\n",
      "          (3): CausalConvolutionBlock(\n",
      "            (causal): Sequential(\n",
      "              (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(8,))\n",
      "              (1): Chomp1d()\n",
      "              (2): LeakyReLU(negative_slope=0.01)\n",
      "              (3): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(8,))\n",
      "              (4): Chomp1d()\n",
      "              (5): LeakyReLU(negative_slope=0.01)\n",
      "            )\n",
      "            (upordownsample): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): AdaptiveMaxPool1d(output_size=1)\n",
      "      (2): SqueezeChannels()\n",
      "    )\n",
      "    (linear_mean): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (linear_sd): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (1): Softplus(\n",
      "        (softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): CausalCNNVDecoder(\n",
      "    (linear1): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (linear2): Linear(in_features=64, out_features=12800, bias=True)\n",
      "    (causal_cnn): CausalCNN(\n",
      "      (network): Sequential(\n",
      "        (0): CausalConvolutionBlock(\n",
      "          (causal): Sequential(\n",
      "            (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(8,))\n",
      "            (1): Chomp1d()\n",
      "            (2): LeakyReLU(negative_slope=0.01)\n",
      "            (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(8,))\n",
      "            (4): Chomp1d()\n",
      "            (5): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "          (upordownsample): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): CausalConvolutionBlock(\n",
      "          (causal): Sequential(\n",
      "            (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
      "            (1): Chomp1d()\n",
      "            (2): LeakyReLU(negative_slope=0.01)\n",
      "            (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
      "            (4): Chomp1d()\n",
      "            (5): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "        (2): CausalConvolutionBlock(\n",
      "          (causal): Sequential(\n",
      "            (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (1): Chomp1d()\n",
      "            (2): LeakyReLU(negative_slope=0.01)\n",
      "            (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "            (4): Chomp1d()\n",
      "            (5): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "        (3): CausalConvolutionBlock(\n",
      "          (causal): Sequential(\n",
      "            (0): Conv1d(128, 1, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "            (1): Chomp1d()\n",
      "            (2): LeakyReLU(negative_slope=0.01)\n",
      "            (3): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "            (4): Chomp1d()\n",
      "            (5): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "          (upordownsample): Conv1d(128, 1, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out_sigmoid): Sigmoid()\n",
      "  (classif_stage): Sequential(\n",
      "    (0): Linear(in_features=480, out_features=3, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (classif_age): Sequential(\n",
      "    (0): Linear(in_features=480, out_features=2, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (w_folds): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (1): Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      ")]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3880218/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 15\n",
    "    params['encoder']['depth'] = 3\n",
    "    params['decoder']['depth'] = 3\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split15_ecgTrue_rrFalse_rspFalse_20240922084657/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "print(networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e481592c-d4c4-4e38-ae26-102074d4e263",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "[[334 167  42]\n",
      " [138 362  69]\n",
      " [ 19  64   3]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[122   1 159]\n",
      " [ 14  52 236]\n",
      " [  9   2  37]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[410  87 168]\n",
      " [  0 416 254]\n",
      " [  0  62  42]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[356 255  50]\n",
      " [ 11 575  65]\n",
      " [  0 117   6]]\n"
     ]
    }
   ],
   "source": [
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        # input_rr = batch_data['rr']\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        \n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557bc269-f7bb-454b-a09a-8a5070d19407",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922095352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9751243-cf3e-4ca3-9be0-220d8f47a493",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 17:55:51,683 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 2, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 5, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922095352/models', 'n_class': 3}\n",
      "/tmp/ipykernel_262861/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 38400])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 600])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 600])\n",
      "[[303 143  97]\n",
      " [ 52 375 142]\n",
      " [ 10  64  12]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[132   0 150]\n",
      " [  5  16 281]\n",
      " [  7   0  41]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[410 153 102]\n",
      " [  7 602  61]\n",
      " [  1 103   0]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[360 254  47]\n",
      " [  4 573  74]\n",
      " [  0  77  46]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 5\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922095352/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3aecb6-abc5-433d-9daf-6625af30689f",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240922095435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c67c4e-f983-4114-8f2d-b89c658b19f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 18:08:47,027 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 2, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 1, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240922095435/models', 'n_class': 3}\n",
      "/tmp/ipykernel_262861/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 192000])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 3000])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 3000])\n",
      "[[384 155   4]\n",
      " [151 405  13]\n",
      " [ 15  58  13]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[198   5  79]\n",
      " [ 58  51 193]\n",
      " [ 17   2  29]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[440 124 101]\n",
      " [  0 645  25]\n",
      " [  0  99   5]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[419 231  11]\n",
      " [ 26 589  36]\n",
      " [  1  85  37]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 1\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240922095435/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0cc2ca-9c73-480c-a95d-81ae8a7de0f6",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923171358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f8559d-f60c-47f6-876f-a160aaf2b233",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 19:24:04,967 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 1, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 10, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923171358/models', 'n_class': 3}\n",
      "/tmp/ipykernel_453062/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 19200])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 300])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 300])\n",
      "[[502  32   9]\n",
      " [391 160  18]\n",
      " [ 60  25   1]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[275   5   2]\n",
      " [182 111   9]\n",
      " [ 36   8   4]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[478 113  74]\n",
      " [119 506  45]\n",
      " [  7  94   3]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[461 193   7]\n",
      " [ 40 551  60]\n",
      " [  3  81  39]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 1\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923171358/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5591ba-f2b0-4eb5-af7b-d5d31b9460b8",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923212500\n",
    "w_folds sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd333db-f530-4f3e-8329-7d812b4a6519",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 14:25:09,417 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 5, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 10, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923212500/models', 'n_class': 3}\n",
      "/tmp/ipykernel_1892809/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 19200])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 300])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 300])\n",
      "[[398 125  20]\n",
      " [190 322  57]\n",
      " [ 32  52   2]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[259   0  23]\n",
      " [ 43  38 221]\n",
      " [ 14   2  32]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[446 207  12]\n",
      " [ 87 582   1]\n",
      " [  6  98   0]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[385 264  12]\n",
      " [ 13 625  13]\n",
      " [  2 110  11]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 10\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923212500/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5198e9-3457-4234-bbb3-706a6b5267dc",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240923212653\n",
    "w_fold sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "521df47c-c98e-422f-b830-12c6378c59ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 14:40:49,692 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 5, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 5, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240923212653/models', 'n_class': 3}\n",
      "/tmp/ipykernel_1892809/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 38400])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 600])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 600])\n",
      "[[369 174   0]\n",
      " [121 446   2]\n",
      " [ 23  63   0]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[217   4  61]\n",
      " [ 25 125 152]\n",
      " [  9   9  30]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[493  95  77]\n",
      " [518 151   1]\n",
      " [ 74  29   1]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[424 230   7]\n",
      " [ 19 591  41]\n",
      " [  0 104  19]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 5\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240923212653/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5939cbc-e638-495f-90d5-bf190b11736b",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240923212948\n",
    "w_fold sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08224105-4366-4a66-a1e6-ba3d18f65a3c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 14:47:06,572 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 5, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 1, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240923212948/models', 'n_class': 3}\n",
      "/tmp/ipykernel_1892809/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 192000])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 3000])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 3000])\n",
      "[[391 123  29]\n",
      " [195 325  49]\n",
      " [ 29  49   8]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[142   6 134]\n",
      " [ 28  53 221]\n",
      " [ 15   3  30]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[450 136  79]\n",
      " [110 548  12]\n",
      " [ 13  87   4]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[374 244  43]\n",
      " [ 12 603  36]\n",
      " [  0 107  16]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 1\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split1_ecgTrue_rrFalse_rspFalse_20240923212948/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        # if i_batch > 20:\n",
    "        #     break\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    if not os.path.exists(PRED_PATH):\n",
    "            os.makedirs(PRED_PATH)\n",
    "    df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    cm = confusion_matrix(df['label'], df['pred'])\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628664f-b92e-4782-ac5a-6419f23aa13e",
   "metadata": {},
   "source": [
    "## interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16741bdf-91f9-4557-8472-5d830caf10b6",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922095352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b977e9ba-5319-4f6f-8dc4-aad679c35ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz(input_dict, output_dict, pred_label):\n",
    "    ecg = input_dict['ecg']\n",
    "    label = input_dict['label']\n",
    "    w_folds = output_dict['w_folds']\n",
    "    print(w_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eea5d84-6fb7-4207-9146-95a773589030",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 20:26:36,013 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 4, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 5, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922095352/models', 'n_class': 3}\n",
      "/tmp/ipykernel_453062/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 38400])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 600])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 600])\n",
      "[[[3.7578816]\n",
      "  [4.0928783]\n",
      "  [4.1091123]\n",
      "  [4.0690665]\n",
      "  [4.0928807]]]\n",
      "[[[3.8910453]\n",
      "  [3.6651144]\n",
      "  [3.7998817]\n",
      "  [3.754382 ]\n",
      "  [3.8289568]]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[[4.057015 ]\n",
      "  [3.8933315]\n",
      "  [3.9902282]\n",
      "  [3.98851  ]\n",
      "  [4.0107975]]]\n",
      "[[[4.094333 ]\n",
      "  [4.0213866]\n",
      "  [3.9737496]\n",
      "  [4.1505523]\n",
      "  [4.1435766]]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[[3.8552692]\n",
      "  [3.8565664]\n",
      "  [3.9318542]\n",
      "  [3.7820506]\n",
      "  [3.8359659]]]\n",
      "[[[3.8497415]\n",
      "  [3.725282 ]\n",
      "  [3.6938684]\n",
      "  [3.7513123]\n",
      "  [3.8710113]]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[[3.9553504]\n",
      "  [3.9205894]\n",
      "  [3.898716 ]\n",
      "  [3.7342958]\n",
      "  [3.5716352]]]\n",
      "[[[3.9631627]\n",
      "  [4.0528116]\n",
      "  [3.8874521]\n",
      "  [3.8552194]\n",
      "  [3.8900783]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 5\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240922095352/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        w_folds = net_outputs['w_folds']\n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "        viz(batch_data, net_outputs, pred_label)\n",
    "        \n",
    "        if i_batch > 0:\n",
    "            break\n",
    "    \n",
    "    # df = pd.DataFrame.from_dict(outputs)\n",
    "    # print(df)\n",
    "    # break\n",
    "\n",
    "    # PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    # if not os.path.exists(PRED_PATH):\n",
    "    #         os.makedirs(PRED_PATH)\n",
    "    # df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    # cm = confusion_matrix(df['label'], df['pred'])\n",
    "    # print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d747fed-6eb6-4fd4-ae01-bdd73454bbef",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923171358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07866dc0-7b1d-4a83-b2ad-4a4d96c28560",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 20:36:05,325 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 4, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 10, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923171358/models', 'n_class': 3}\n",
      "/tmp/ipykernel_453062/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 19200])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 300])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 300])\n",
      "[[[3.3500228]\n",
      "  [2.9673443]\n",
      "  [2.8897953]\n",
      "  [2.8967133]\n",
      "  [2.884591 ]\n",
      "  [2.9173658]\n",
      "  [2.8957458]\n",
      "  [2.8873274]\n",
      "  [2.902593 ]\n",
      "  [2.884305 ]]]\n",
      "[[[3.0590782]\n",
      "  [3.211787 ]\n",
      "  [3.1286564]\n",
      "  [3.1204486]\n",
      "  [3.2453623]\n",
      "  [3.0135236]\n",
      "  [3.2506585]\n",
      "  [3.2497792]\n",
      "  [3.1632965]\n",
      "  [3.1217778]]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[[3.0755224]\n",
      "  [3.0859282]\n",
      "  [3.1682942]\n",
      "  [2.8469477]\n",
      "  [3.0505128]\n",
      "  [3.2077549]\n",
      "  [3.049256 ]\n",
      "  [2.9630485]\n",
      "  [3.0404098]\n",
      "  [3.0135956]]]\n",
      "[[[3.1640422]\n",
      "  [3.0309644]\n",
      "  [3.0764604]\n",
      "  [3.0469217]\n",
      "  [3.074613 ]\n",
      "  [3.1716413]\n",
      "  [2.9640095]\n",
      "  [3.1125612]\n",
      "  [2.9666576]\n",
      "  [3.1040323]]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[[3.1071196]\n",
      "  [3.1318352]\n",
      "  [2.8964837]\n",
      "  [3.1012104]\n",
      "  [3.0781229]\n",
      "  [3.0522585]\n",
      "  [2.883082 ]\n",
      "  [3.0746279]\n",
      "  [3.1323028]\n",
      "  [2.9518044]]]\n",
      "[[[3.01189  ]\n",
      "  [2.9571407]\n",
      "  [3.0372918]\n",
      "  [3.023843 ]\n",
      "  [2.953178 ]\n",
      "  [3.136538 ]\n",
      "  [2.9831383]\n",
      "  [2.9306479]\n",
      "  [3.0989652]\n",
      "  [2.9546905]]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[[3.1408262]\n",
      "  [3.108264 ]\n",
      "  [2.8691695]\n",
      "  [3.1130912]\n",
      "  [3.0114527]\n",
      "  [3.1108894]\n",
      "  [3.0508666]\n",
      "  [3.2648792]\n",
      "  [3.0801978]\n",
      "  [3.294332 ]]]\n",
      "[[[3.12999  ]\n",
      "  [3.1226664]\n",
      "  [3.048625 ]\n",
      "  [3.0832906]\n",
      "  [3.1334238]\n",
      "  [3.084256 ]\n",
      "  [3.310767 ]\n",
      "  [2.9248421]\n",
      "  [2.9651458]\n",
      "  [3.0545447]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 10\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split10_ecgTrue_rrFalse_rspFalse_20240923171358/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "\n",
    "        viz(batch_data, net_outputs, pred_label)\n",
    "        \n",
    "        if i_batch > 0:\n",
    "            break\n",
    "        \n",
    "    # df = pd.DataFrame.from_dict(outputs)\n",
    "\n",
    "    # PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    # if not os.path.exists(PRED_PATH):\n",
    "    #         os.makedirs(PRED_PATH)\n",
    "    # df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    # cm = confusion_matrix(df['label'], df['pred'])\n",
    "    # print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804eb608-e78d-4831-9222-49978280df29",
   "metadata": {},
   "source": [
    "### simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240923212653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea219071-0f9c-464b-a194-df1a7bf092d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 15:13:59,282 - __main__ - DEBUG - {'batch_size': 128, 'cuda': 5, 'data_path': 'data/mesa/polysomnography/set1', 'early_stop_delta': 0.001, 'early_stop_patience': 30, 'hz': 100, 'hz_rr': 5, 'lr': 0.001, 'lr_scheduler_patience': 10, 'max_epoch': 200, 'min_lr': '1e-6', 'seg_len_sec': 30, 'seg_len': 3000, 'n_split': 5, 'age_classif': False, 'input_ecg': True, 'input_rr': False, 'input_rsp': False, 'input_ecg_beats': False, 'encoder': {'in_channels': 1, 'channels': 128, 'depth': 5, 'reduced_size': 64, 'out_channels': 32, 'kernel_size': 5, 'dropout': 0.3, 'softplus_eps': 0.0001, 'sd_output': True}, 'decoder': {'k': 32, 'width': 3000, 'in_channels': 64, 'channels': 128, 'depth': 5, 'out_channels': 1, 'kernel_size': 5, 'gaussian_out': False, 'softplus_eps': 0.0001, 'dropout': 0.0}, 'model_path': 'logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240923212653/models', 'n_class': 3}\n",
      "/tmp/ipykernel_1892809/1596233174.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(model_file, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution: ['0:543', '1:569', '2:86']\n",
      "1198 1198\n",
      "--CausalCNNVDecoder linear1:torch.Size([1, 64])\n",
      "--CausalCNNVDecoder linear2:torch.Size([1, 38400])\n",
      "--CausalCNNVDecoder reshape:torch.Size([1, 64, 600])\n",
      "--CausalCNNVDecoder out_causal_cnn:torch.Size([1, 1, 600])\n",
      "[[[0.96702933]\n",
      "  [0.96865326]\n",
      "  [0.96959376]\n",
      "  [0.9681911 ]\n",
      "  [0.9685289 ]]]\n",
      "[[[0.9732972 ]\n",
      "  [0.97599345]\n",
      "  [0.97545195]\n",
      "  [0.97697794]\n",
      "  [0.9710222 ]]]\n",
      "label distribution: ['0:282', '1:302', '2:48']\n",
      "632 632\n",
      "[[[0.9706645]\n",
      "  [0.9730259]\n",
      "  [0.9737205]\n",
      "  [0.9729946]\n",
      "  [0.9723219]]]\n",
      "[[[0.9711194 ]\n",
      "  [0.9730809 ]\n",
      "  [0.97311586]\n",
      "  [0.9737607 ]\n",
      "  [0.9729188 ]]]\n",
      "label distribution: ['0:665', '1:670', '2:104']\n",
      "1439 1439\n",
      "[[[0.9683159 ]\n",
      "  [0.9712496 ]\n",
      "  [0.9732074 ]\n",
      "  [0.97241014]\n",
      "  [0.97198063]]]\n",
      "[[[0.9726098 ]\n",
      "  [0.9708603 ]\n",
      "  [0.97382385]\n",
      "  [0.97243416]\n",
      "  [0.971796  ]]]\n",
      "label distribution: ['0:661', '1:651', '2:123']\n",
      "1435 1435\n",
      "[[[0.9749416 ]\n",
      "  [0.97554636]\n",
      "  [0.974323  ]\n",
      "  [0.97070235]\n",
      "  [0.966887  ]]]\n",
      "[[[0.97568953]\n",
      "  [0.9764133 ]\n",
      "  [0.9771823 ]\n",
      "  [0.9751601 ]\n",
      "  [0.97963434]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = None \n",
    "CFG_FILE = 'config_multimodal_ecg.yml'\n",
    "with open(CFG_FILE, 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "    params['seg_len'] = params['hz'] * params['seg_len_sec']\n",
    "    params['decoder']['width'] = params['seg_len']\n",
    "    # override specific params\n",
    "    params['n_split'] = 5\n",
    "    params['encoder']['depth'] = 5\n",
    "    params['decoder']['depth'] = 5\n",
    "    \n",
    "config_logger()\n",
    "params['model_path'] = \"logs/simMultimodalEcgNoAge_config_multimodal_ecg_datamesapolysomnographyset1_split5_ecgTrue_rrFalse_rspFalse_20240923212653/models\"\n",
    "class_map = {0:0, 1:1, 2:1, 3:1, 4:1, 5:2}\n",
    "params['n_class'] = len(set(class_map.values()))\n",
    "log(params)\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{params['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "networks = init_load_models(params)\n",
    "# print(networks)\n",
    "\n",
    "\n",
    "\n",
    "for test_rec in test_rec_names:\n",
    "    p_ds = datasource.PartialDataset(\n",
    "        dataset=ds, seg_index=ds.record_wise_segments[test_rec]\n",
    "    )\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset=p_ds, batch_size=1, shuffle=False, drop_last=False)\n",
    "    print(len(p_ds), len(data_loader_test))\n",
    "\n",
    "    outputs = []\n",
    "    tp, tn = 0, 0\n",
    "    for i_batch, batch_data in enumerate(data_loader_test):\n",
    "        input_ecg = batch_data['ecg'].to(DEVICE)\n",
    "        label = batch_data['label'].detach().cpu().numpy()[0]\n",
    "        net_outputs = networks[0](input_ecg)\n",
    "        cls_proba = net_outputs['clz_proba'] \n",
    "        # cls_proba = networks[1](z)\n",
    "        pred_label = torch.argmax(cls_proba, axis=1).detach().cpu().numpy()[0]\n",
    "        # print(label, pred_label)\n",
    "        outputs.append({\n",
    "            'label': label, 'pred': pred_label\n",
    "        })\n",
    "\n",
    "        viz(batch_data, net_outputs, pred_label)\n",
    "        \n",
    "        if i_batch > 0:\n",
    "            break\n",
    "        \n",
    "    # df = pd.DataFrame.from_dict(outputs)\n",
    "\n",
    "    # PRED_PATH = params['model_path'].replace('models', 'preds')\n",
    "    # if not os.path.exists(PRED_PATH):\n",
    "    #         os.makedirs(PRED_PATH)\n",
    "    # df.to_csv(f\"{PRED_PATH}/{test_rec}.csv\")\n",
    "\n",
    "    # cm = confusion_matrix(df['label'], df['pred'])\n",
    "    # print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83de40c-a825-451a-b455-b422dfb5c752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
